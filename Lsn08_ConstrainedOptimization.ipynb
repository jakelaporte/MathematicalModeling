{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Lsn08_ConstrainedOptimization.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakelaporte/MathematicalModeling/blob/master/Lsn08_ConstrainedOptimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rrG7P3Y9RQU",
        "colab_type": "text"
      },
      "source": [
        "## Constrained Optimization - Mathematics\n",
        "In this R notebook, we consider the mathematics behind the numerical methods that involve Lagrange multipliers using examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFU8EUL09RQX",
        "colab_type": "text"
      },
      "source": [
        "#### Recall from Lsn 5, we solved this equation as an unconstrained optimization ####\n",
        "$$\\max_{x,y}{f(x,y)=xy-2x-2y-x^2-y^2 }$$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrf14Xpi9RQa",
        "colab_type": "code",
        "colab": {},
        "outputId": "e1cfa2a5-08c1-48a7-e70a-f2233e170e91"
      },
      "source": [
        "# Unconstrained Optimization (from class)\n",
        "f = function(x){(x[1]*x[2]-2*x[1]-2*x[2]-x[1]^2-x[2]^2)*-1}\n",
        "x0 = c(1,1)\n",
        "optim(x0,f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<dl>\n",
              "\t<dt>$par</dt>\n",
              "\t\t<dd><ol class=list-inline>\n",
              "\t<li>-2.00003060365125</li>\n",
              "\t<li>-2.00012907759956</li>\n",
              "</ol>\n",
              "</dd>\n",
              "\t<dt>$value</dt>\n",
              "\t\t<dd>-3.99999998635264</dd>\n",
              "\t<dt>$counts</dt>\n",
              "\t\t<dd><dl class=dl-horizontal>\n",
              "\t<dt>function</dt>\n",
              "\t\t<dd>71</dd>\n",
              "\t<dt>gradient</dt>\n",
              "\t\t<dd>&lt;NA&gt;</dd>\n",
              "</dl>\n",
              "</dd>\n",
              "\t<dt>$convergence</dt>\n",
              "\t\t<dd>0</dd>\n",
              "\t<dt>$message</dt>\n",
              "\t\t<dd>NULL</dd>\n",
              "</dl>\n"
            ],
            "text/latex": "\\begin{description}\n\\item[\\$par] \\begin{enumerate*}\n\\item -2.00003060365125\n\\item -2.00012907759956\n\\end{enumerate*}\n\n\\item[\\$value] -3.99999998635264\n\\item[\\$counts] \\begin{description*}\n\\item[function] 71\n\\item[gradient] <NA>\n\\end{description*}\n\n\\item[\\$convergence] 0\n\\item[\\$message] NULL\n\\end{description}\n",
            "text/markdown": "$par\n:   1. -2.00003060365125\n2. -2.00012907759956\n\n\n\n$value\n:   -3.99999998635264\n$counts\n:   function\n:   71gradient\n:   &lt;NA&gt;\n\n\n$convergence\n:   0\n$message\n:   NULL\n\n\n",
            "text/plain": [
              "$par\n",
              "[1] -2.000031 -2.000129\n",
              "\n",
              "$value\n",
              "[1] -4\n",
              "\n",
              "$counts\n",
              "function gradient \n",
              "      71       NA \n",
              "\n",
              "$convergence\n",
              "[1] 0\n",
              "\n",
              "$message\n",
              "NULL\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUN3BtRs9RQl",
        "colab_type": "text"
      },
      "source": [
        "Suppose that there are the two constraints that $x+y=7$ and $-2x+y=7$ so that the feasible solution must meet both of these two constraints. <br><br>\n",
        "$$\\max_{x,y}{f(x,y)=xy-2x-2y-x^2-y^2 }$$ <br>\n",
        "$$ \\text{s.t. }x+y=7$$\n",
        "$$-2x+y=7$$<br><br>\n",
        "Turning these constraints into matrix form and doing one step of row reduction, we see that the feasible solutions for $x,y$ are very limited.<br><br>\n",
        "$$\\begin{bmatrix}1&1&:&7\\\\-2&1&:&7\\end{bmatrix}\\begin{array}{c}2\\\\ \\hspace{1pt}\\end{array}\\Longrightarrow \\begin{bmatrix}1&1&:&7\\\\0&3&:&21\\end{bmatrix}\\Longrightarrow \\begin{array}{c}x_1=7\\\\x_2=7\\end{array}$$\n",
        "<br> Notice that there is only one solution and it was rather trivial to find. Do we need to consider the objective function? What if we added another constraint to the problem? We could possibly over constrain the problem and not have a solution. Think back to your linear algerbra class when the matrix was **Full Column Rank**. The solution to those types of matrices (and thus, constraints here) is either one solution or no solution. Therefore, the objective function is not considered because there is only one feasible solution which turns this into a Linear Algebra problem instead of a Constrained Optimization one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5t5fCOd9RQn",
        "colab_type": "text"
      },
      "source": [
        "#### Change the problem so that we need the objective function\n",
        "Instead of those two functions above, let's use the first one only so that the problem is not over-constrained.\n",
        "$$\\max_{x,y}{f(x,y)=xy-2x-2y-x^2-y^2 }$$ <br>\n",
        "$$ \\text{s.t. }x+y=7$$<br><br>\n",
        "Let's look at the objective function and the constraint on the same contour plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg5hhYK-9RQp",
        "colab_type": "code",
        "colab": {},
        "outputId": "6a973d96-bb0a-43e6-a6cf-86ae60137459"
      },
      "source": [
        "library(ma391laporte)\n",
        "#help(Outer) - I put an example in my documentation to get out a contour plot\n",
        "X = list(x=seq(-10,10),y=seq(-10,10))\n",
        "Z = Outer(f,X)\n",
        "contour(x=X$x,y=X$y,z=-Z,lwd=3)\n",
        "abline(a=7,b=-1,col=\"red\",lwd=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM\njIyampqnp6eysrK9vb3Hx8fQ0NDZ2dnh4eHp6enw8PD/AAD///89ODILAAAACXBIWXMAABJ0\nAAASdAHeZh94AAAgAElEQVR4nO2djXrbOo8GlTZfmtOmWd3/1W4tx4mT+IciX4AAOfPsttk9\nEgCTmFCibHdZAaCZpXcBACOASAACEAlAACIBCEAkAAGIBCAAkQAEIBKAAEQCEIBIAAIQCUAA\nIgEIQCQAAYgEIACRAAQgEoAARAIQgEgAAhAJQAAiAQhAJAABiAQgAJEABCASgABEAhCASAAC\nEAlAACIBCEAkAAGIBCAAkQAEIBKAAEQCEIBIAAIQCUAAIgEIQCQAAYgEIACRAAQgEoAARAIQ\ngEgAAhAJQAAiAQhAJAABiAQgAJEABCASgABEAhCASAACEAlAACIBCEAkAAGIBCAAkQAEIBKA\nAEQCEIBIAAIQCUAAIgEIQCQAAYgEIACRAAQgEoAARAIQgEgAAhAJQAAiAQhAJAABiAQgAJEA\nBCASgABEAhCASAACEAlAACIBCEAkAAGIBCAAkQAEIBKAAEQCEIBIAAIQCUAAIgEIQCQAAYgE\nIACRAAQgEoAARAIQgEgAAhAJQAAiAQhAJAABiAQgAJEABCASgABEAhDgINIyNP/3j941gJqK\nLteL0yFFV/6Z1LsE0IJIXcCk0UCkPmDSYCBSJzBpLBCpF5g0FIjUDUwaCUTqx/+h0jggUkcw\naRwQqSuYNAqI1BdMGgRE6gwmjQEi9QaThsBVpD+/Hrf39z0+/bFKkRBMGgFHkV5/nL1X9qdJ\nipxg0gA4ivS0PPz3sv309/fD8mSRIimYlB9HkR6Wl/efX5YHixRZ4YFSehxF+vTZp9sfhJpN\nJExKDytSEDApN773SL//bj9xj3QBTEqN5/b3z7Ndux+vJikyg0mZ8X2O9LQ9R3p4/MVzpAtg\nUmJmemdDzTe92Ab6wrtJVgnAjDgiNX63UVkCVRxLk+xGAOyII5J1igQeHbfB8Sgjs4ik6k7b\n5eL9yyOtEoAVk4gkan9rjQ6w5ZAS13c2FN8GiXtV1f+mHr0PCyZlxFGk514ipdJoxaSUeF7a\nvTzc/vCEIMXFYEKP2sPcCP4efRyTlmv0LkyO6z3Sy+03BilSfA+VZjk6+3+kNOmqNCX0Lr4Z\n382G57P3rRql+Bop/nJ0qZMymdQk0DBODb5rp5kZywm+0j0JTGqxYjybhhZJNCX+Gq2RP6Fk\n0fz5bRpZJM1kGM7pzX6JZ5LP6pFUp4FFEnokqOZK5FuxA5nkvWDks2lYkaIvRyUNEsKkfldc\nqWwaVSTJwPfVaO1tUoxGjlBDAWOKpBlza48KDuxlUgyHrtTTuZbLDCnSKBqtPUyK5tAHEWt6\nZ0SRdB61BrkauDyyp0lhFfogbHHjiRR7OdrfBV7b4OEdOhGzyOFECr0cVTWAg0lZHDoRsNjR\nRFKMrtUUVc+9rUm5HDoRreixREqwHFWdamZSspXoM6FKH0qk+MtR7dkWJqWW6I04r2AkkWQe\nNca4FrYlrtqkESw6EuR1DCRS3OVIMdFCk8aR6I0IL2cckQZejjZEJo0m0RvdX9QwIoX1SDa/\n7SYNtxR9ou8rG0UkkUeNIS4HVYVte6A0tERvdHx9g4g0g0ctJs1g0Ua31ziISKvks0fNIb5F\nVM9qnUmTSHSk0yvNLpJkzEK8O7WM/SZNZdFGl1ebXiRBPYoYF6LazOdOk6az6ECPl5xcpGXX\n0XYxvgc1m8sdJs23GJ3wf9WpRVqimmTavoUmzWvRAfeXnlmkZW2WYPmIIXxZxrNYYtLcGh1w\nfvV5RXobpXcTKvMsp0iyl2XfwPe2wbHogO8QpBZpG6eGrYKTQEuTjV/Lcpi+myZh0QnPYcgr\n0r+DzheU+jzHEJk8Wq9f3rEYneM4EjlFWk5rUctl3cmepU3Gr3U5zdxFk7DoK27DkVSkt/Wo\noZpjCIO7I1Wwe3wzicXoEl4jklKk5eN/G2+P0t0dnfHZJCy6gtOw5BTp/bquZb/O4u5IE6qQ\nD5NYjG7hMjIpRRJU8b4U5bs7+uDNJCy6g8fwZBapdWwargy/RurUyIdtcDQqwH6EEovUXIds\nt65fJ59M6pE7FeZTlFMk1XKUXKND3oNJPXKnw3iWUorUstW2fOxSCJcjRaCavEeTOmRPiO0v\nvIwitRTwNpay50e9lqOzOyNMKsVyrjKK1BBXPZJ9NPqy241JpRhO11Qiqcexz3L0fZsOk4ox\nm7CZRDLxSBivOOe3vJhUjNWczSPSCMvR1WdGmFSM0bRNI5J4/EJptPr9u34DYDNzk4ik7nt/\nj25ZdACTijGZuzlEGl6jA5hUjMH0TSGShUe6cIUJ7+fEpGL0MziBSNmXozKLDmBSMfI5HF+k\n5MtRuUYrJu1APY3Di5Tbo10arZi0A/XTEJdT+qWYSqMVk3Ygbg2XU3qlSL0cVWi0sg2+A+ls\nDi2StvFddxkKN+ougEnFKOdzZJEMPJJFK8hVnQ6TSkGkoiBZl6M2jVZMKkY4p8OKlHY5arXo\nACYVopvWUUXK6pFCoxWTipFN7KAiSTs/nUYrJhWjmtsxRcq5HOk0WjGpGES6cbp6OfLwSKrR\nikmliAZ9QJFSXtapNVp5oFSKZtzHE0nZkM7LkTgoJpUhGfrhRJJ7JIp1N49FIkwqQjH6o4mU\ncDmyzINJRSDS1/PyLUcGN0fnYFIJghkYSiRhSzotR8YarZhURvskjCSS2iNNqHtZrPNgUgnN\n8zCQSNku61w0WjGpjNapGEekZMuRl0Yr2+BlINLbKak8ctRoxaQiGudjEJF0benS4a4aHcCk\n+7RNyRgiiT2SRLqTw1OjFZNKaJqVIUSSNaZHi/fQaMWkElomZgSRMi1HvjdH52DSfeYWKZFH\n/TRaMamAhsnJL5LUI0mgmxl6abRiUgH185NdJO02gyTQzQz9NFoxqYDqKUouUiKPumu08kCp\ngDlFwqOdYNI9aqcptUjadzNoIl2PH8Cjlcu7u0wokrI3Tbs8jkYrJt1jOpFEzen2aQnzNKVg\n0k0q5yqtSCqPzF9PMI1WTLrDXCLpPLJ9QfE0WjHpNnUTllQk7XJk94pCeoRJt5lIJN1yZCpS\nUI1WtsFvUjVpGUVSXtZ92CQnrkYrJt1kEpGE23XLYrfdENqjlcu7G8whkqw/lzeHTLo9ukYr\nJl2nZurSiSTsT7v7owQarZh0nQlEEjXox53RpMvRBiZdoWL6kokku6w7rUYGLyaLRus+k5ZP\nGBYVgdFFEr7Z+/wvJbn67J5JSylO9Xqx/yXlEknV+XZvDMrWVpdMKrZnYKdGFyl4joSddP5A\nqVyQ4W1CpPIcRpd18qjGHE1qFGI4m3aXP6dIJhvfaZvnn0lCAQbRCZFuxrXb8s65HB1b/d0k\ncdzMNu0teiqR3gYHjw6ct7nNA6XcNiHS9ah2c5msT741uOGj2awy7Sx2HpEspzFRi1zpa+M3\nOWR0CZEuh7SbwjTtcWttcHi7UDKVEOliRGOPbEILuXuB5fMJpUQu7atyEpHmvqwru7Dy+qxf\nGpcQ6Vu4mZejHXcnXu8GT6LSrgpnEGlij3be4vt9riKFSoj0OdisHlXc3Ht+Qim+SYj0Kdac\nGlVYdMD1s37RVdpT3fAiTelRpUUHfD81G1wlRPqIZDVPcVugwaIDmPQBIr0HMvXIJHIbjRYd\ncP4mh8gqIdJbmNk8arfogPeXR8ZVaUddI4tkNj8xJ15j0YE+JsUb0T1L0sAizeWRzKIN7y/q\nimoSItndHkWcc91idML9K+8iDisircYeWQSuR27RAf8vj4yoUnlFo4o0jUf6xegNTDowuUhW\nMxJupq0sOtDhC43Dje/kIs3ikaVGa5+vBg82wnOLNIdHxhYd6PGvkYUa47lFQiMZmFRczXgi\nTeCR2QbDdzBpVpFspiHShpKfRQdmN2lWkQw90oetwHExemNyk+YUyajFwnjkbtGBubfBSysZ\nSiSb8Q8zq100WjFpOpGG9qiXRQemNmk+kUa+rOup0Tr3o9npRBp4Oeqs0Tr1A6XCMoYRaVyP\nult0YG6TSo6qCLz/lHOefyzL4291CotBj9DAMTQ6MK1J4UQ61vPz2BhP2hRmHqmDVpTQvYo3\nZjUppkhPy9Pruv59Wp6VKcb0KJRG67QmldXgLdLD8nr4+XX5oUth0W39OziaRuvMJhUcVBF3\n/ynH85bTH2d/n//nM/bFHdCjeBYdmNOkkCL97yTSgyrFiB7F1Gid1KR4Ij3+ev69/Pfvx9en\n27sNO1JY3R6pY+5M3717rtBhG7z7WMQT6b1BluXhVZNivOUoskZrL5OcM1bk93yO9PLy/Pz4\nuG05PN30qDzFcB4F1+hAl6+88834LX/BQRVx959ilWI0jxJotM5nUlH61CIZeSQOuSt3fI3W\nKU26f0xF2IpSTFLohzfActQr+y56mOSbcHf2xCKN5VEijdY+X7LvmvBr9vvHVIStKMUgxVAe\n5dJoncykoUWy8UgbcVfqVB51+TeUPNPtzp1VpJE8SqjR6m5S57vX+8dUhK0oRZ1iII9yanRg\nGpPGFQmPQjCLScOKJB/Sbs2cWaO1g0mO2XYmzijSMB4l12h1NqnrVcPdYyrC1tQiTIFHgZjG\npLuHVEStKUWXwsQjacDytNk1Wv1N8ku2L286kQbxaBCNVl+TOt7K3j2kImpNKaoUeBQOzwdK\niCRKMYZHI2m0uprU7zL87iEVUWtK0aRQj2OXhh5MowOuJjll2pk1l0gXvnyoKQ0eiXAzqduV\n+N1DKqLWlBIuxdrHoyE1Wn1N8km0M+nEIqGREi+Tut3U3jukImpVLdFS4JEYR5Nc8uxMOq1I\nvTxyzumIk0m9lqR7R1QErSolWIpOHjmn9MVpGxyR4qTosDYMvhxt+JjUaav13hEVQatKiZQC\nj6zwMsk+yd6UM4rk39RD7zJ8wsMkRIqRguXIEgeT+tzf3juiImhVKWFSsBzZ4mOSdYrdGacT\nqY9Hrhk7Y28SIvVP4d3Vky1HG+Ymdbk4v3dERdCqUmKk6OKRZ8IQeJhkm2B/wrlEcm7rGZej\nDesHSojUO4W/R475AmFsEiJ1TME7VF0xNanHjtG9IyqCVpXSOYV7V8+t0Wpvkl3wqnzTiLS6\nXtdNvhxtWJqESJ1SHMfBbfDR6IChSR2uL+4dURG0qpSeKZZTRJ/BZzl6w9Ykq9B16SYQ6djW\nfksSGr1jZ5L/c4x7h1REraqlX4rj7dE2Eh6l49EZZtvg7iLdPaQiak0p/VKcbo98GhyNPmNl\nku8wI9JHsMWjcJaj79iZZBG2OtnYIp1tMXgMOxpdwsYkRHJNcXTI8/bIPk06TExyHWtEertB\n8hh1NLqKlUn6oPW5RhfJ7QESHt3AwiREckzhdE234tEdDExCJO8UXtsMDmnyojfJc8gRySDa\npQR4dBf9AyVE8k5hXTAelSA3CZH8UrgMNR4VIjbJcdjnFem07d1eyv1MaFSK3iRluLZMY4rk\n/B5V+zSDoDUJkaxT+DU3Hu1DahIiGafw9cgn0ygoTUIk2xR4FBmhSaHmeTyR3Lqby7oqdNvg\nniLdP6YibEUpfinwKDoykxDJMAUeJUBkEiLZpXD1yCXRkGhMQiSzFHiUBIlJiGSWAo+yoDAp\n1GwPJZJTf3N7JEBgkqNIBQdVxN1/ik8KPMpEu0mIZJMCj3LRbBIimaRw9MghzQy0PlBCJIsU\neJSPRpOcpqJsykcRyafBuawT02SS3+/OkqMqAu8/xTwFHiWl1SRdJY1ZxhAJj9LSYhIiiVP4\neWSfZToaTEIkcQo8yky9SYikTeHS4nhkRrVJkX6BDiASHmWndhvcS6Siwyoi7z/FMgUe5afS\nJEQSpsCjIagyCZF0KfBoEGpMQiRZCjwahgqTEEmVAo8GYr9JkWY/tUh4NBS7TXKa/rLjKkLv\nP8UmhUeL87YgR/aahEiaFHg0GjtNQiRJCocexyNn9j1QQiRFCiePjFPAZ3aZ5HRJUnZgRez9\npxikwKNB2WGSj0iFB1bE3n+KPgUeDUu5SYjUnAKPBqbUJKdd28IDK2LvP0WdAo+GptCkSLdI\nOUXCo8EpMynSgpRSJDwaniKTEKktBR5NQMk2OCI1pcCjKSgwKVQjpBMJj2bhrkkunVB8aEX0\n/afoUuDRPNwzCZHqU+DRTNwxCZGqU+DRXNw0yX6m9mRIJ5J1ZjyKxC2TQi1IyUSyzs3HJqJx\nwyRECpHicl48isb1bXBECpHiYlo8isdVkxApRIpLWfEoJFdMCrXXgEhnSfEoKJdN8hBpx8EV\n8fefEjDF95x4FJaLJiFSiBTfUuJRYC6ZhEghUnzNiEehuWCS9YztawlEOibEo+B8M8l8yvbF\nR6QtHx6F56tJsa7sEGlLh0cJ+PJACZFipDjPhkcp+GxSrFskRMKjRJybFOsWCZFcPvoPIs5M\nQqQYKT5yIVIiPkwynra9bTG9SHiUi5NJ1vO2N/zsIuFRNt5MCnZlN7tIeJSPo0nBruwmFwmP\nMrJtgwe7sptbJDzKycEkRAqSYsWjxBxMsoy/vzUmFgmPErP3H0Dfyf7WmFckPMrMYmsSIpWn\nwKPE/Js8S5MqmmNWkfAoNYfZMzSpojkmFsk8B5ixTZ+dSYhUnACRUnOcPiuTarpjTpHwKDen\n+Sv5d/3qwu8/pyLN/lOCpcCj5LzPn4lJVe0xo0h4lJ2zCTQwqao9JhQJj9JzPoN6kxCpLDYe\nZefzFKpNqmuQ6UTCo/x8mUKxSXUNMptII3u0HOldhj1fX6TWJEQqCTxooy3f6V2SId9endKk\nyrGbS6QRG+yCQ4PrdOF1CbfBKwdtOpGMIvfgsjXj63TpBelMyiDSn1+P27w+Pv2xSnE77DA9\ndV+VgX26/EpEJtWOk6NIrz/O5vSnSYrbjNFLu/QYUqYrr0JjUu0QOYr0tDz897L99Pf3w/Jk\nkeImA7RRpRRjmXT1RUhMSiDSw/Ly/vPL8mCR4mbM9E3UqsMgJl1/CQKTqgfIUaRPFX4v1/rX\nZvoWkozNACbdeAXtJlUPzzQrUvoOEv2CyT4Mtyey1aT6Mfa9R/r9d/upwz1Sdo9k63Tycbj3\nAhpNqh8dz+3vn2fXbj9eTVJcDZi8f3TXu9lH4l6vNz1Qahgc3+dIT9tzpIfHX97PkXJ3j/S+\nMfdQ3O/1FpMaxmaOdzbk/jWs3X5JPRRF5Veb1DLOU4iER5/D6YK5UzQWtSa1DM0sImkDOiJ/\nGpB5MEqrrzOpaaRnECnzgqR/qpZ4MMqnssqkppGZQCQ8+hZSG9GR4tprTEKk27HyNo7Nmzzy\njsee2veb1DbYU4gkjOaJ0Zul8g7Irl7fvQ3eNi7Di5R3QeJNh9/YVfpOkxpHe3SR0npkpVFm\nkfYOyS6TGodlcJHw6GJom8Dm7K58h0mt4z2+SKpQnkjfE3QpuFFoY/YXXm5S66CMLVLSnrHU\naE3726VqNktNah7xoUXCo2vxDaPbUVV3oUnNYzK6SJpAnlhrlHRY1tq6y0xCpFtRMnaMvUdZ\nRaodmBKT2gd9YJHw6EYO4xQWVFdd8ECpfUTGFSlju3hotGZdkuqrvmuSYNiHFkkQxRUnjzIO\nTWOz3zFJMCDDipRwQfLyKK1IDWffNEkx7qOKlNQjt0w+iZQ0Fn3LJMV4DCySoA5PHNXPNziC\n4blhEiJdD5CuVzwrzjc6ima/apJkOMYUKV+n+FacbngkJV8zSTIaQ4qUziO3bYaPfI7ZFEgG\n6PI2uGbsRxVJU4cX3uanGyBRxRdN0oQeUaSUC5J3Qtd8zchG6LtJotADioRH4RI2oyv4m0mi\n0GOKpKrDBf+2zjZC0iH6YpIq9HgiZft126HeZCMkLvizSarQw4mER0U5vVM2IR6jc5NkoUcU\nSVeHPV28TzZG8nrPTJKFHk2kZAtSL48yjZFBve8m6UIPKJKwDmv6tHSuMTKp9/RASRd6MJFy\n/bLtVG2qMTIapaNJwtBjiYRHhXl7pK3FqNyDScLQw4kkrcOUbtanGiW7YfpnEiJdOS1Ti/T0\nKM8oWWp/MEkWbDSRtHVY0q3YVKNkqf3S8O+ffw/mcopPilS/avsVm2mUTIdpUZo0kEh4VJy6\nU+YKLItdlCaNJZK6DjN6Ss84ncXe/e/6XY3mcopHikwLUmeP0oyT9YK0VvwLmdeiuZzikSJR\nf3Tt5UTjZL8gHdCYNIxIiX7R9i01zzh5LEgHJCaNJJK+DhM6K59noHwWpFVj0igi5VmQelea\nZqC8FqRVYtJAIhnUYUAAj5KMlNuCtCpMGkSkNO3RvdDe+XfgtiCtApPGEKl7e5bSv9DuBRTj\nuCCt7SYNI5JJHWr6e5RmqHwXpLX5gdIQIgXozzIC1BmghDJ8F6S11aRRRLKpQ0wA4QOUUIjz\ngnSgxaQRRErTHAHqDFBCGe4L0oEGkwYRyagOMf0LTfM7p8eCtLaYNIBINMeeAvIMlf+CtDaY\nNIZIVnVo6d/G3QsopZdH9SblF6l/e5bSvVCGqiB2pUnpRcrTHN1FyjNU/RaktXYbfASR7OrQ\nwrvsSunpUaVJ2UXK1R2dPz7BSBWGrjBpAJEM65CCR4UYX9iVHLbfpOwieVQjomsnJ/Ko84Xd\nkd0mpRcpDz1bOZlHfS/sNvaahEhe9OzlTB4ZL0jFx+40KbNIC/1RnDrVOAVYkNa9JiUW6XhQ\nmhbp18x4VBd61zZ4epHSmNStm1N5FOXCbmOPSYlFejfJsBAd3do5nUdRFqQD5SblFWk5LUY5\n2qTngtQncRWRFqQDxSalFenoUJ5ftyxIJQRbkNZykzKLlKpHOtWaaowCelRsUlaRluNBabqk\nU0Pn8ijchd1GmUlZRToNTJY2waMCIi5Ia6FJaUVKtdPQSSQ8Oo9df3KJSXlF+nfQksajLiIl\n8yjEm1Uv8/5A6XqQxCIlukPq0tMJPYp4YbfxZtKNMJlFStQmeHSfqBd2Rw4m3RpSRHLBv6kz\nehR2QTrwz6RbYRKLlKlP3Lsajz7HFkQ5mHQjx/6AUURKhHtbp/Mo8E7De5ibm3c5RUrWJO4L\nUkqPQl/YbWFumZRSpIxt4pwu2QAF32k4hblhUkaRMvaJa7KE45NhQVpufUIpqUj2JeQFjwxC\nn8JcNQmRRgOPvsbWhrliUkKREnaKIxlHJ8GO3VmYyyblFMm+AinLEa9UHnmU5LmwO3LRpHwi\n5WuV5dNftqnSDU6yC7uNSyalFMm+ACXLl78tU6UbnDXbhd3GBZMQyRw/kbJ6lOrCbuO7SelE\nStgsXrdICYcm44XdxjeTMopkn1+N1+1RvqEx9shoQVq/P1BCpEHI6VHGG6Q3vpiUTaSc7XLA\ntGy//XUtSS/sjnwyKaFI9uktMC08qUZ5L+yOnJuUTKSkDbPaioRHZrFvhzkzKZ9I9tlNsN3k\nzTkqxr9cHMJ8mIRITph1e2qPci9I65lJuURK2zOr1e+ArLsMq/Fk+ixI64dJ6USyT26ESe15\nNbK/a3QKc/rKu4roFRWpUmRtmtWmb5J7lP7CbuNoUjKREqPvm8waDXJhd2T78siK8PtPCZjC\nHXnn4JFx8PIwt7/y7mr8/acETOGPuHVSezTKDdKJPf/++UeC/acETOGPtHdyazTUhd0GIvmh\n7B08Mg++MwyXdm7omifxw6Mj43mESH7Imj+7RuNd2K2I5IluivHIOvjuMIjkh2SK02s0pkeI\n5IhijvHIJfj+MIjkR+ssL0v6XYY8HiFSYGpFWM4xqMsR21fQzyNEcmXZq8TyDfMaTTH3qNOF\nHSI5812Ma5NWfGAm0niESAm4KNPH5A1p0BvjeoRI/bgq1IgKbZgvSKIwNXEQqTszKLSR5sKu\n6jSXUwKmiMe4Bh1J4xEiQWDG9giRwAfjtVYVvToOIoEL5h71XZAQCVwY/MIOkcCFHB61LJuI\nBPbkuUFCJIiLvUe9L+wQCeyZwSNEAnOMHzIHuEFaEQnMmWJBQiQwZg6PEAlsmcSjDiI9/1iW\nx9+mKSAM1u/CjXGDtLqKdCz15/Etzk8mKSAYDh7FWJDcRXpanl7X9e/T8myRAoIxjUfuIj0s\nr4efX5cfFikgFrPcIK3+In18M4FFCgjFNDdIq79I/zuJ9GCRAiIxzw3S6izS46/n38t//358\nfbq924BIAzCVR74ivX8nwbI8vFqkgDjM5ZHrc6SXl+fnx8dty+Hpu0fLObUpIArmsxjpBmnl\nnQ1gg4dHkRYkRAILpvOoi0j3S0ek3MznESKBngk9QiSQk8Yj5TuYEAnEpPIIkSAoc3qESKBl\nUo/Y/gYps3qESKAkj0fqj0ohEujI5REiQUwm9giRQIb9u43jeoRIoMLFo5AbDVtIl1MCpgAx\niTyy+E4WRAIJyTxCJAjJ7B4hEiiY3iNEAgF4hEjQTiaPrL78FZGgFYdvq5F61BDq+qmIBI34\neBTiwu7GyYgEbczlESKBDXj09h8r4tWXEigFSEjlUeOt1s2zEQkaSOeR1YKESFDPgkcf/7ki\nYnUtkVJAMx4eSb8xy+7CDpGgGi+PUixIiASVeGiUxyNEgjrw6MsRFUHragmWAprAo6+HVESt\nqiVaCmgBj74dUxG2ppZwKaCBuTwq2u5DJNjNfB4hEujBo0tHVQTef0rAFFALHl08rCLy/lMC\npoBKsnnU/oaGotMRCXaR0SPjDbvjgRWx958SMAVUMZlH5csZIkE5Lm+vC+YRIoEaPLpxaEX0\n/acETAG7waNbx1aE339KwBSwFxeNsnqESFDIdB7t2zdHJCjB57IumkeIBFoSetT6IfWdtSAS\n3MfJI+n3cnveIK2IBAU4aRTpwm736YgE98CjkjMqkuw/JWAKKMTrsi6SRxXXmIgEN5nVI0QC\nJXhUek5Fmv2nBEwBJXhplN4jRIIb4FH5WS6nBEwBd3G7rBvAI0SCa+DRrvNcTgmYAm6z4NG+\nE11OCZgCbuKn0RgeIRJcIqlHzW/Wqz8fkeAbjhqN4hEiwTcye9QYrP50RILPOO4yhPOoJbnL\nKQFTwGU8NRK3flOw5m0Kl1MCpoCLJPVoOfuzOkDbBy9cTgmYAi7gqpHUI8nNUdOK5nJKwBTw\nHRxImXMAAAhoSURBVPflSLkete7XffxZX4P5KQFTwDeyetR+YSeIgUhwxP+yTrcetVlwLGUr\nB5Ggkay3R5sBS8vF3Wmfoa0mRILV+eGR2KNjwLVJpObNCkSC1Xs5knu0rUn1bzeVmIRIkNmj\nRomOIc7+bAxifUrAFHDCWSP1O3ma7o+OxTTuM6yVBSDSUCT26GwpadlokNSESJOT2KPzlaRN\nJEUtLqcETAEHvDWy+fhR/TuEEAkU9FiOhPneBWp6jqqRCZEmJrlH6+n9CO1RJLU4nBIwBXS5\nrNMnbI64SNoNkWYl9+3RedymkzXrESLNivN7glY7j5qQeYRIc+KukYlHjf+W2KpsNESaETyS\nF4RI8+Gvkb5tW5cT+RAg0nQM4VH7N0GKhwCRJsN/l2Ekj66fhUhz0UGjkTy6fh4izUSP5Wgs\njxAJ+mk0gUeINA941Bbg9omINAldNJrHI0Sagz4amdwexfQIkWZgwaOzCDYnItLw9NRoGo+y\niYRhu+mkUcDbI0uPkonUpSNS00uj2TzKJxIm7aCbRgZvCo3tUTKRMGkPvW6O1gk9yiYSF3fl\n9NNoQo8yioRJJXTWaBiPSn91ZxMJk4roqNF4Ho0pEibdp+PN0aweJRSJ26Q7dNXI4rOnGTxK\nKhImXaerRtN6lFEkTLpBf43m9CilSFzcXaOvRjN7lFYkTPpO35sjE4vTeJRTJEy6QGeNTL5W\nJY9HSUXCpK/01mh2j7KKxG3SJ4bUKJVHmUXCpDe6a4RHeUXCpBNBNLK4rEvkUV6RuLjb6K+R\n3XKUyaPEIvGx8xAa4dHbSRV59p8SMMUADKuR4rrd2SNESksEjfDo4zSXUwKmSE4IjfDo7DyX\nU2xSHF9x927qQAyNjHZOU3qUWqSDQ8f/mYtAGo3mUf1ecG6RjhL17ylPgmiER1/OdDnFMEWA\nlvIkikZjetTQ3KlFOq5H6zwPZ2fQqJtHbZlzi/T2x2EIAnSXMUsYjcb0qE2l1CIdV6N3n4Ym\nkEZDerQ23m3nFmm7plvGF2mJpJHV+4UVYVv2Gd7/qD/d/BTTFMM/TQplkdVy1NWjj9Vozs2G\nj4OjdJmeWIvRmB6dPUWZXKQwbaYmmEWhb4+a9+uaHu67ivTn1+M2Yo9Pf5Qp3scvUMNJmEWj\nAB4tbeuRq0ivP5YPfhqkiNV0rYSzaFSP3jZ+GytwFOlpefjvZfvp7++H5ckgRbjOqyeqRlFv\njxrfz9C4HNWdXZvwYXl5//llebBIEa/7qoi2wbBhVlBfjz4cSiPSp1d6+2W3/G6J1oC7iWjR\nuB69W5Tn0s5hRdrODdiF5YRcjCxvPztf153Wo/a3VLicsvHvHun33+0nq3uk09kBO7GIoBYZ\nL0dd74/ab47OAtmfcuTn2a7dj1eTFG+nx2zH2yyxNRrTo5NIgiJcTnnjz9P2HOnh8Zf0OdKl\nADFb8ipxLbK+rOu8X7eKPBrhnQ1XQgRtywtEtij87VF7lEXS0cOKlEWl2BZZPuQO4VHKeyT3\nFIEb9Ehwi8b3aHt/XXsV6+AiBTcpukUzeNReQn0kw5HVt1bgRo1ukarZDUMHGj/XdzYUu6Ic\nnTBD/Y04XXANwwI1oeOMoKNIz31EAnDA89Lu5eH2hycEKQD64HqP9HL7jUGKFABd8N1seD57\n36pRCoAexNm1c04BoASRAAQgEoCAHiLd3/xHJEgGIgEIQCQAAYgEIACRAAQgEoAAtr8BBCAS\ngABEAhCASAACEAlAACIBCEAkAAGIBCAgqEgAyajocr04KXKXQH1tTFUfIl2H+tqYqj5Eug71\ntTFVfYh0HeprY6r6EOk61NfGVPUh0nWor42p6kOk61BfG1PVh0jXob42pqoPka5DfW1MVR8i\nXYf62piqPkS6DvW1MVV9iHQd6mtjqvqiv1iAFCASgABEAhCASAACEAlAACIBCEAkAAGIBCAA\nkQAEIBKAAEQCEIBIAAIQCUAAIgEIQCQAAYgEIKCbSM+nzE8Py8PTa68yblH9heoexB22jdBj\nZ9F8vV7qy2mQf24D/qNTGbd4idwMcYdtI/TYmTRfp5f68vD2Wv4sDy+H/+tPnzpu8bI89i7h\nKoGHbSPy2Nk0Xx+Rnpefb6/lafn978//ll9d6rjJc8Si3gg8bBuRx86m+fqItDytb6/lcfm7\nBv0F9rw89y7hKoGHbSPy2Nk0Xx+RXtbTa/n8Vygel9//+3cr2ruMiwQeto3IY2fTfN1mIoNI\nGz9713GJwMO2EXnsVkTyZVn+W9fXp5AXKYGHbSPy2K2I1IPXkHvM4YdtI+bYrflFOn+28Pb3\nQ7yO+PIEJFJp7wQctktErc+g+XqLdNw4+Rtp+ymDSAGH7RIhx241ab7el3a/tq3830vADZ6H\n5fDekZjNGnjYNiKP3WrSfL1FCvyI/ukwwK/Hh3bRCDxsG5HHbjVpvt4irT/C7pO+Pmylxfyl\nH3fYNkKPnUnzdRfpdXsDbq8qbnIo7UfQDdzAw7YReexMmi/o3SBALhAJQAAiAQhAJAABiAQg\nAJEABCASgABEAhCASAACEAlAACIBCEAkAAGIBCAAkQAEIBKAAEQCEIBIAAIQCUAAIgEIQCQA\nAYgEIACRAAQgEoAARAIQgEgAAhAJQAAiAQhAJAABiAQgAJEABCASgABEAhCASAACEAlAACIB\nCEAkAAGIBCAAkQAEIBKAAEQCEIBIAAIQCUAAIgEIQCQAAYgEIACRAAQgEoAARAIQgEgAAhAJ\nQAAiAQhAJAABiAQgAJEABCASgABEAhCASAACEAlAACIBCEAkAAGIBCAAkQAEIBKAAEQCEIBI\nAAIQCUAAIgEIQCQAAYgEIACRAAQgEoAARAIQgEgAAhAJQAAiAQhAJAABiAQgAJEABCASgID/\nB+EkdWyOCinQAAAAAElFTkSuQmCC",
            "text/plain": [
              "plot without title"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlY5ANQu9RQv",
        "colab_type": "text"
      },
      "source": [
        "From yesterday, we know how to find the solution to this problem using R. \n",
        "```R\n",
        "library(MASS);library(NlcOptim)\n",
        "Aeq = matrix(c(1,1),nrow=1)\n",
        "Beq = matrix(7)\n",
        "solnl(x0,f,Aeq=Aeq,Beq=Beq)\n",
        "```\n",
        "Using Lagrange Multipliers, we get the following:<br><br>\n",
        "$$\\vec{\\triangledown}f = \\lambda \\vec{\\triangledown}g$$<br>\n",
        "$$\\begin{bmatrix}y-2-2x\\\\x-2-2y\\end{bmatrix} = \\lambda \\begin{bmatrix}1\\\\1\\end{bmatrix} $$<br>\n",
        "$$g(x,y)=x+y=7$$<br>\n",
        "Solving these three equations for $(x,y,\\lambda)$, we get the same solution as the R code renders. $(x,y,\\lambda)=(3.5,3.5,-5.5)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SsHJ3m19RQx",
        "colab_type": "text"
      },
      "source": [
        "## Linear Algebra approach\n",
        "Let's use the idea of the nullspace of the constraint matrix from Linear Algebra.  The complete solution to $A\\vec{x}=\\vec{b}$ can be found by finding the nullspace of the one constraint (a much simpler problem than you are used to, but it will hopefully make the point here). Understand that there can be numerous constraints on the problem with numerous decision variables and that this is a simple example to show how to use the constraint matrix. Here, there is $m=1$ constraint and $n=2$ decision variables. Our matrix will always be an $A_{m\\text{x}n}$ and will hopefully have a nullspace larger than the zero vector. For the problems where the nullspace is only the zero vector (see the one with two constraints above), there is either one or no solution and the problem is not really an optimization problem because the objective function is not considered. In this problem, we have **Full Row Rank** (although it is only one row) with $n-r=2-1=1$ dimensions in the nullspace. This means that the answer lies somewhere on the line (see the contour plot) and this constitutes our **feasible region**. Solving this problem from this approach allows us to use numerical methods to step towards the answer because we are able to stay in the nullspace of the constraint matrix with our steps. Let's solve this problem in order to gain insight into what is going on.<br><br>\n",
        "$$ \\begin{bmatrix}1&1&:&0\\end{bmatrix}\\Longrightarrow \\text{ special soln }\\Longrightarrow x_{null}= \\begin{bmatrix}-1\\\\1\\end{bmatrix}$$<br><br>\n",
        "Use the nullspace to turn the problem into an unconstrained optimization.\n",
        "$$x_{\\text{complete}} = x_{\\text{particular}}+x_{\\text{null}}=\\begin{bmatrix}0\\\\7\\end{bmatrix}+\\lambda \\begin{bmatrix}-1\\\\1\\end{bmatrix}\\Longrightarrow \\begin{array}{c}x = -\\lambda\\\\y = 7+\\lambda \\end{array}$$<br><br>\n",
        "Since the dimension of the nullspace is only one, there is only one variable in the new objective function. Had the dimension been 2, then there would have been two variables and so on. The new unconstrained objective function is found by substitution of $x,y$ into the original objective function:<br><br>\n",
        "$$f(\\lambda)=(-\\lambda (7+\\lambda)-2(-\\lambda)-2(7+\\lambda)-(-\\lambda)^2-(7+\\lambda)^2 $$<br>\n",
        "Go back and look at the red line on the contour plot that represented the constraint. Notice how it is impossible to select a $\\lambda$ which will not be on that line!!! Therefore, we can simple solve this problem by optimizing $\\max_{\\lambda}{f(\\lambda)}$.The R code below will finish this optimization using Newton's method and the derivative."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOg3p1i49RQy",
        "colab_type": "code",
        "colab": {},
        "outputId": "0c695a70-4e73-42b5-c0b5-65a91c1320aa"
      },
      "source": [
        "library(ma391laporte)\n",
        "f = function(x){-x*(7+x)-2*(-x)-2*(7+x)-(-x)^2-(7+x)^2}\n",
        "#help(fprime) # used the fprime newton's method to solve this function numberically\n",
        "dF = function(x){fprime(f,x)}\n",
        "ans = newton(dF,10)\n",
        "print(ans)\n",
        "#this is not the same lambda (I should have used another variable)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] -3.500002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRuMG5YR9RQ4",
        "colab_type": "text"
      },
      "source": [
        "#### How do we use this answer $\\lambda$ to find $x,y$?\n",
        "Our optimal $\\lambda$ is -3.5 and we remember the relationship between $x,y$ and $\\lambda$.\n",
        "$$\\begin{array}{c}x = -\\lambda\\\\y = 7+\\lambda \\end{array}$$\n",
        "So $x = -(-3.5)=3.5$ and $y = 7+(-3.5)=3.5$ and we get the same answer as the analytic solution of Lagrange multipliers, which should not surprise you. This leads to a numerical algorithm which can solve all of our problems and not just the ones that have an analytic solution. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qct1f0e49RQ5",
        "colab_type": "text"
      },
      "source": [
        "## Linear Optimization\n",
        "Linear Optimization is special. The gradient will never be equal to zero (just like the derivative of a 1D linear function ever be zero), therefore we should understand that the optimal lies on the boundary in the form of the corner points of the feasible region. The method of optimizing a linear \"program\" is known as the Simplex Method (developed by George Dantzig during WWII to assist in logisitics operations) which can be used to solve problems with thousands of variables and constraints.<br> <br>\n",
        "We will use the lpSolve package in R to solve linear optimization problems.\n",
        "```R\n",
        "install.packages(\"lpSolve\") # use this inside R Studio\n",
        "lp (direction = \"min\", objective.in, const.mat, const.dir, const.rhs,transpose.constraints = TRUE, int.vec, presolve=0, compute.sens=0,binary.vec, all.int=FALSE, all.bin=FALSE, scale = 196, dense.const,num.bin.solns=1, use.rw=FALSE)\n",
        "```\n",
        "where <br><br>\n",
        "- ```direction```: Character string giving direction of optimization: \"min\" (default) or \"max.\"\n",
        "- ```objective.in```: Numeric vector of coefficients of objective function\n",
        "- ```const.mat```: Matrix of numeric constraint coefficients, one row per constraint, one columnper variable (unless transpose.constraints = FALSE; see below).\n",
        "- ```const.dir```: Vector  of  character  strings  giving  the  direction  of  the  constraint:  each  valueshould be one of \"<,\" \"<=,\" \"=,\" \"==,\" \">,\" or \">=\". (In each pair the two valuesare identical.)\n",
        "- ```const.rhs```: Vector of numeric values for the right-hand sides of the \n",
        "- ```constraints.transpose.constraints```: By default each constraint occupies a row of const.mat, and that matrix needs tobe transposed before being passed to the optimizing code.  For very large con-straint matrices it may be wiser to construct the constraints in a matrix column-by-column. In that case set transpose.constraints to FALSE.\n",
        "- ```int.vec```: Numeric vector giving the indices of variables that are required to be integer.The length of this vector will therefore be the number of integer variables.\n",
        "- ```presolve```: Numeric: presolve? Default 0 (no); any non-zero value means \"yes.\" Currentlyignored.\n",
        "- ```compute.sens```: Numeric: compute sensitivity? Default 0 (no); any non-zero value means \"yes.\"; Gives shadow prices. Inside ```ans$duals```\n",
        "- ```all.int```: Logical: should all variables be integer? Default: FALSE. \n",
        "- ```all.bin```: Logical: should all variables be binary? Default: FALSE.\n",
        "\n",
        "<br>\n",
        "Let's solve a simple problem using this library and function.\n",
        "$$ \\min_{x_1,x_2,x_3,x_4}{50x_1+20x_2+30x_3+80x_4}$$ <br>\n",
        "$$\\text{s.t. }400x_1+200x_2+150x_3+500x_4 \\ge 500 $$\n",
        "$$3x_1+2x_2 \\ge 6$$\n",
        "$$2x_1+2x_2+4x_3+4x_4 \\ge 10$$\n",
        "$$2x_1+4x_2+x_3+5x_4 \\ge 8$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo_iXZZi9RQ7",
        "colab_type": "code",
        "colab": {},
        "outputId": "14797038-70e6-4b93-dfb3-5786bd095323"
      },
      "source": [
        "library(lpSolve)\n",
        "f.obj = c(50,20,30,80)\n",
        "f.con = matrix(c(400,200,150,500,3,2,0,0,2,2,4,4,2,4,1,5),nrow=4,byrow=T) \n",
        "f.dir = c(\">=\",\">=\",\">=\",\">=\")\n",
        "f.rhs = c(500,6,10,8)\n",
        "ans = lp(\"min\",f.obj,f.con,f.dir,f.rhs,compute.sens = T)\n",
        "print(ans$solution)\n",
        "print(ans$objval)\n",
        "print(ans$duals)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] 0 3 1 0\n",
            "[1] 90\n",
            "[1]  0.0  2.5  7.5  0.0 27.5  0.0  0.0 50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbxXl-pB9RQ_",
        "colab_type": "text"
      },
      "source": [
        "Note that the solution to this problem is $x_1=0, x_2=3, x_3=1, x_4=0$ with an objective value of 90. The \"duals\" or \"lambdas\" in the problem are 0 for the non-binding constraints (1st and 4th). The last 4 constraints are ones that we do not have to put into the problem and are assumed $x_1,x_2,x_3,x_4 \\ge 0$. From the solution, we note that the $x_1=0$ and $x_4=0$ are also binding constraints. There should be a positive lambda for each binding constraint.\n",
        "\n",
        "## Summary of R commands used in Optimization when to use them:\n",
        "\n",
        "| R command | Library | Circumstance   |\n",
        "|--------|------------|-----------|\n",
        "| optim() | base R |unconstrained optimization  | \n",
        "| solnl() | MASS, NlcOptim |constrained nonlinear optimization |\n",
        "| lp() | lpSolve | linear optimization (sometime called linear programming|"
      ]
    }
  ]
}