{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.6.1"
    },
    "colab": {
      "name": "Lsn05_MVOptimization.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jakelaporte/MathematicalModeling/blob/master/Lsn05_MVOptimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7qmgwPm-D6M",
        "colab_type": "text"
      },
      "source": [
        "## Lesson 5 Multivariable Optimization (pages 21-31)\n",
        "Example 2.1 Color TV Sales\n",
        "\n",
        "**Facts/Variables:**<ol>\n",
        "- $s$ = number of 19-inch TVs sold (per year)<br>\n",
        "- $t$ = number of 21-inch TVs sold (per year)<br>\n",
        "- $p$ = selling price of a 19 in set (\\$)<br>\n",
        "- $q$ = selling price of a 21 in set (\\$)<br>\n",
        "- $C$ = cost of manufacturing sets (\\$/yr)<br>\n",
        "- $R$ = revenue from sale of sets (\\$/yr)<br>\n",
        "- $P$ = profit from the sale of sets (\\$/yr)<br>\n",
        "</ol>\n",
        "\n",
        "**Assumptions** <ol>\n",
        "- $p$ - selling price of 19in set is affected by the number of 19in & 21in TV sets sold: $p=339-0.01s-0.003t$\n",
        "- $q$ - selling price of 21in set is affected by the number of 19in & 21in TV sets sold: $q=339-0.004s-0.01t$\n",
        "- $R$ - revenue is made only from selling these two TV sets: $R = ps+qt$\n",
        "- $C$ - there is a fixed cost and enough of other materials not to cause any additional cost for making more sets: $C = 400000+195s+225t$\n",
        "- $P = R-C$\n",
        "- $s\\ge0$\n",
        "- $t\\ge0$\n",
        "</ol>\n",
        "\n",
        "**Objective:** Maximixe $P$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWqRmEpN-D6R",
        "colab_type": "text"
      },
      "source": [
        "#### Numerical Calculation using a form of Newton's Method ####\n",
        "Let's start by recalling single variable newton's method and using that to understand multi-variable version.<br>\n",
        "The general form of a numerical method lies in using the previous value and adding some step that makes the next value better: $x_{n+1} = x_n+p$ the step in this equation is the step $p$. Newton's method (as we derived in class) uses the derivatives to find the best step.<br><br>\n",
        "$x_{n+1} = x_n-\\frac{f(x_n)}{f'(x_n)}$ solves for the root of $f(x)$ <br><br>\n",
        "When trying to find an optimal point, we substitute the derivative in for the function to find the root of the derivative.<br> <br>\n",
        "$x_{n+1} = x_n-\\frac{f'(x_n)}{f''(x_n)}$ solves for the root of $f'(x)$. <br><br>\n",
        "This numerical method allows us to take steps toward optimal point. Here, let's take $x_n$ to the left side and isolate the step so that we can use this same process for multivariable. $x_{n+1}-x{n} = p = -\\frac{f'(x_n)}{f''(x_n)}$ which turns into $\\boxed{f''(x_n)p=-f'(x_n)}$. This is the same formula that we will use for the multivariable newton's method to find the direction of the next step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTSXbMvx-D6U",
        "colab_type": "text"
      },
      "source": [
        "#### Multivariable Newton's Method ####\n",
        "Starting the same as above except with vectors this time, we see that $\\vec{x}_{n+1}=\\vec{x}_n+\\vec{p}$. All we need to do is find the direction $\\vec{p}$. Using the boxed equation and Linear Algebra instead of simple algebra, we need to solve the following equation at each step of process:<br><br>\n",
        "$$ \\vec{\\triangledown}^2 f(x_n)\\vec{p} =  -\\vec{\\triangledown} f(x_n)$$ <br>\n",
        "where $\\vec{\\triangledown}^2 f(x_n)$ is the Hessian Matrix and $\\vec{\\triangledown} f(x_n)$ is the gradient.<br><br>\n",
        "If we perform this method for large problems, then it would cost a lot of calculations to find the Hessian matrix at each step. This computationally expensive requirement is usually relaxed in the non-linear optimization by finding and updating an approximation to the Hessian at each step. The method used by many was developed by Broyden, Fletcher, Goldfarb, and Shanno and is known by their initials (BFGS). The idea behind their method is to use the difference between the gradients and previous locations to create a rank 2 update to the previous Hessian that preserves both symmetry and positive definiteness of the Hessian matrix. We will not use our own code to find the optimal point, so it is not helpful to review their method. This is a topic for our non-linear optimization course, but it is not difficult and you are only asked to understand that it is simply updating the Hessian matrix using the gradient at each step. This relaxation of calculating the Hessian makes this method known as a Quasi-Newton method.\n",
        "\n",
        "#### Use the Quasi-Newton BFGS method ####\n",
        "The last idea that you need to understand before using the method in practice is that it is for a minimization. As described in lesson 1, positive definiteness relates back to finding minimums. So, what do we do we are maximizing a function? Do we take all of these ideas and reverse them or is there another way?? We can turn any maximization into a minimization by simply multiplying the objective function by a -1 which is much easier than having two different systems for min and max. So that is what we will do in practice. The Transform step above got us to maximizing a profit - we will minimize the negative of this function (see below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7O-_XRE-D6X",
        "colab_type": "code",
        "colab": {},
        "outputId": "f02fc8cf-2a5f-45a4-83d7-3be4a9291d8d"
      },
      "source": [
        "P = function(x){\n",
        "    return(((339-0.01*x[1]-0.003*x[2])*x[1]\n",
        "           +(399-0.004*x[1]-0.01*x[2])*x[2]\n",
        "           -(400000+195*x[1]+225*x[2]))*-1)\n",
        "}\n",
        "x=c(500,500) #starting point for optimization\n",
        "ans = optim(x,P,method=\"BFGS\") #BFGS is a numerical technique used to incrementally calculate the Hessian for Newton\n",
        "print(ans)\n",
        "paste(c(\"Profits are maximized by selling:\",round(ans$par[1]),\" 19 in TVs and \",\n",
        "        round(ans$par[2]),\" 21 in TVs. Resulting in a profit of: $\",\n",
        "        format(round(-P(ans$par)),big.mark=\",\")),collapse=\"\")\n",
        "paste(c(\"Average Selling Price of 19 in set is: $\",round(339-0.01*ans$par[1]-0.003*ans$par[2],2)),collapse=\"\")\n",
        "paste(c(\"Average Selling Price of 21 in set is: $\",round(399-0.004*ans$par[1]-0.01*ans$par[2],2)),collapse=\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "$par\n",
            "[1] 4735.043 7042.735\n",
            "\n",
            "$value\n",
            "[1] -553641\n",
            "\n",
            "$counts\n",
            "function gradient \n",
            "       8        5 \n",
            "\n",
            "$convergence\n",
            "[1] 0\n",
            "\n",
            "$message\n",
            "NULL\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Profits are maximized by selling:4735 19 in TVs and 7043 21 in TVs. Resulting in a profit of: $553,641'"
            ],
            "text/latex": "'Profits are maximized by selling:4735 19 in TVs and 7043 21 in TVs. Resulting in a profit of: \\$553,641'",
            "text/markdown": "'Profits are maximized by selling:4735 19 in TVs and 7043 21 in TVs. Resulting in a profit of: $553,641'",
            "text/plain": [
              "[1] \"Profits are maximized by selling:4735 19 in TVs and 7043 21 in TVs. Resulting in a profit of: $553,641\""
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Average Selling Price of 19 in set is: $270.52'"
            ],
            "text/latex": "'Average Selling Price of 19 in set is: \\$270.52'",
            "text/markdown": "'Average Selling Price of 19 in set is: $270.52'",
            "text/plain": [
              "[1] \"Average Selling Price of 19 in set is: $270.52\""
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Average Selling Price of 21 in set is: $309.63'"
            ],
            "text/latex": "'Average Selling Price of 21 in set is: \\$309.63'",
            "text/markdown": "'Average Selling Price of 21 in set is: $309.63'",
            "text/plain": [
              "[1] \"Average Selling Price of 21 in set is: $309.63\""
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmUN2c7f-D6g",
        "colab_type": "text"
      },
      "source": [
        "## Sensitivity Analysis\n",
        "Choose an assumption and let's analyze how changing that assumption will affect our result. The book chooses price elasticity of 19 inch sets. Let's do the same thing in R to see how we can use R to analyze this assumption and see what happens to the answer as we change this assumption. Let's start by changing our function from above into one that only considers the value of a and calculates the new optimal, since we might need the optimal value or the parameters, let's print out and later return both in a list. Since we know the values (from above) for 0.01, use it as validating our function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOaGCr9m-D6j",
        "colab_type": "code",
        "colab": {},
        "outputId": "6b5f9cde-7e74-4429-ae3b-89bca17dc786"
      },
      "source": [
        "P = function(a){\n",
        "    f = function(x){((339-a*x[1]-0.003*x[2])*x[1]\n",
        "           +(399-0.004*x[1]-0.01*x[2])*x[2]\n",
        "           -(400000+195*x[1]+225*x[2]))*-1\n",
        "    }\n",
        "    x = c(4700,7042)\n",
        "    ans = optim(x,f,method=\"BFGS\")\n",
        "    ## Choose which of these that we will return ##\n",
        "    print(ans$par)\n",
        "    print(ans$value)   \n",
        "}\n",
        "P(0.01)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] 4735.051 7042.736\n",
            "[1] -553641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEIDdEjO-D6q",
        "colab_type": "text"
      },
      "source": [
        "#### Figure 2.5 from the book \n",
        "Let's use the function above and a sequence of a values (looks like the book goes from 0 through 0.02. Since the optimum production value for 19 inch sets is plotted, then that is what we will choose to return in our function (and we will take out the print statements)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cSLxUTy-D6r",
        "colab_type": "code",
        "colab": {},
        "outputId": "064bc134-dd92-41f6-f0e8-43ebd8b93398"
      },
      "source": [
        "P = function(a){\n",
        "    f = function(x){((339-a*x[1]-0.003*x[2])*x[1]\n",
        "           +(399-0.004*x[1]-0.01*x[2])*x[2]\n",
        "           -(400000+195*x[1]+225*x[2]))*-1\n",
        "    }\n",
        "    x = c(4700,7042)\n",
        "    ans = optim(x,f,method=\"BFGS\")\n",
        "    ## Choose which of these that we will return ##\n",
        "    #print(ans$par)\n",
        "    #print(ans$value)   \n",
        "    return(ans)\n",
        "}\n",
        "a = seq(0.002,0.02,0.001)\n",
        "ans.x1=0\n",
        "ans.x2=0\n",
        "ans.profit=0\n",
        "for(i in 1:length(a)){\n",
        "    ans = P(a[i])\n",
        "    ans.x1[i]=ans$par[1]\n",
        "    ans.x2[i]=ans$par[2]\n",
        "    ans.profit[i] = -ans$value\n",
        "}\n",
        "result = data.frame(a=a,x1=ans.x1,x2=ans.x2,profit=format(ans.profit,big.mark=\",\"))\n",
        "print(result)\n",
        "plot(a,ans.x1,xlim=c(0,0.02),ylim=c(0,10000),type=\"l\",ylab=\"optimum x1/x2\",main=\"Figure 2.5/2.6 Book\",\n",
        "     xaxs=\"i\", yaxs=\"i\",col=\"blue\")\n",
        "lines(a,ans.x2,col=\"red\")\n",
        "legend(\"topleft\",legend=c(\"x1\",\"x2\"),lty=1,col=c(\"blue\",\"red\"))\n",
        "grid(lwd=2, nx=4, ny=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       a        x1          x2      profit\n",
            "1  0.002 53612.900 -10064.5124 2,584,516.1\n",
            "2  0.003 23407.877    505.7253 1,329,521.1\n",
            "3  0.004 14972.535   3458.7579   979,027.0\n",
            "4  0.005 11006.446   4847.4863   814,225.2\n",
            "5  0.006  8710.635   5647.0907   718,449.7\n",
            "6  0.007  7197.875   6178.8347   655,844.1\n",
            "7  0.008  6136.679   6553.7258   611,719.4\n",
            "8  0.009  5345.303   6829.6616   578,945.3\n",
            "9  0.010  4735.051   7042.7364   553,641.0\n",
            "10 0.011  4250.122   7212.2779   533,514.1\n",
            "11 0.012  3855.381   7350.3407   517,123.0\n",
            "12 0.013  3527.805   7464.9580   503,515.9\n",
            "13 0.014  3251.579   7561.6335   492,039.1\n",
            "14 0.015  3015.498   7644.2737   482,228.7\n",
            "15 0.016  2811.397   7715.7278   473,746.2\n",
            "16 0.017  2633.185   7778.1230   466,339.1\n",
            "17 0.018  2476.229   7833.0791   459,815.2\n",
            "18 0.019  2336.937   7881.8518   454,025.3\n",
            "19 0.020  2212.485   7925.4288   448,852.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAAAP9NTU1oaGh8\nfHyMjIyampqnp6eysrK9vb3Hx8fQ0NDT09PZ2dnh4eHp6enw8PD/AAD////nTV/EAAAACXBI\nWXMAABJ0AAASdAHeZh94AAAgAElEQVR4nO2di5qiuhJGM3hvd6vt+z/sFhAFRQRSSarCWt85\nG+1hyN/AmpAiorsCgDcudQCAHEAkAAEQCUAARAIQAJEABEAkAAEQCUAARAIQAJEABEAkAAEQ\nCUAARAIQAJEABEAkAAEQCUAARAIQAJEABEAkAAEQCUAARAIQAJEABEAkAAEQCUAARAIQAJEA\nBEAkAAEQCUAARAIQAJEABEAkAAEQCUAARAIQAJEABEAkAAEQCUAARAIQAJEABEAkAAEQCUAA\nRAIQAJEABEAkUVyL+q3vFs+7wrnNsf2jS6uF6t2qf73r9bhxbn3oDdj98ScEfoGFwH4SRVyk\n431ju9bPfjsiHas/7Fvvunn/WStfZ9XPv4/nL7AU2E+iSIv06HxcqwPZd0TaOffzZb1WP9UO\n+DPq9/H7BRYD+0kU6RPv5sL6dL1s68u3O2vnfjvvzr3r3eQqjpVo2/eAl11nk59ApLGwn0R5\nOfGat+dtNSi5v21++nx7XlUXWpfbOKfYnVsbaJzpbLfbyE2X/vUOdVd0cZtN3999vDrewrnt\no9fqvK1Xul03Fu1U8A4iidIv0n1Qs/4o0ur2hzfdinq9Vnez2bi37Z7KE/32v9P1vu1t/3qb\nvt6kLVJRLdf3C727bd231epnPPoOIonSL1LRGTj1iFQPWJrVirfN/j7O82vV07SGPvv2sKiz\nXuFWp81DuJeAZR9ZVRs2j2ibnrfl6je/8egriCRKayh/f3v77089WPkpPoq0vlwrQW7Lcpzz\nVgVYtQsGz3P9XL879a93a/Wt1tAOWJSNltW+w63Vfb3ey9ty9UvRbgE+gEii9Iq0uZ/LPx9F\nqv74ttqlfr952eq6uvJr2K7Lc/20rruUdh/YXe8Z5dT3Q7cpW9s2HVpdk3h5W0k+qry3eBBJ\nlF6RiuZc/yjSpft3X67t1vfeo8upKrudWtq9rFf3dJf1a9Wu0yU1jZcDIff29r76mDtOSweR\nRHF9YyT3VaTmbVvChvPNhFXfGKVa7/AYIr2td5fi0tne4829R3v+YSPSa3T3kAsGQCRRekX6\n3iNVbwvXdzDKIcq685Ntu0K3aYp87+ttus28Bax6vnYX9P62fF/s6ZJGgEii9IrUM0Yqz9bf\nF5E23bLAnfXbabyu1/utxHnY977evh4cXTqXih2RahHbg6LN+xjptyxh0CV9A5FE6RWpqdo1\nF21Fdc7/vhbxytV+q0W7svDaz1RXc8XpeirKIsC5+eOe9cpB1Ol62fTObKjvEY+p2jWz+WAQ\nRBKlV6TX+0jbvopEe7XnHdlTe9XWNWDFqrJu/3G9R528v2pXq7J+vKt0e3lbb2pNAfwriCRK\nv0j3qdnNzIZz/Xb3KlLPDO6Oc82K94kS5V3S7f1ysHe9xooP95Hu7TTqbK89b+tNnd4r8vAC\nIonSL9L1VF5HHbtvf16LDeVcu9XLZ4o6fZl7XpaVc/LKcUszfOlf73pY9cxsuPNo53jbWmeu\nXfE616571xf6QKR4XPpm/0AeIFJ4XD03oLxzwxVSriBSeJ4D+L76NmQBIoXn/BjBUEXOFkSK\nwGVfVqKLLf1RviASgACIBCAAIgEIgEgAAiASgACIBCAAIgEIgEgAAswX6Xdff95ls/v9vjJA\n3swV6bJqfbDl9bOZAEtjrkg7V/zUH1E5HwvmkMHSmStS0fqk14mP2cDSmSvSyxciSEQBsAs9\nEoAAHmOkY/1YT8ZIAPPL362PfboVzw+EheNxH2lX3UcqNnvuI8HioUwAIAAiAQjAFCEAAZgi\nBCAAU4QABOCGLIAATBECEIAeCUAApggBCMAUIQABmCIEIABlAgABEAlAAKYIAQjAFCEAAZgi\nBCAAN2QBBAg0RcgBGCaeSBN6pIiFQe+m/vuv+/6f7wYD8ppVNabCzjmPIkwRQqQwmDo3TYWN\nKdKEKUKWRdJskqlz01TYqCKNnyJkSaQ3FIsEwYgqkqYmwjWFSEsEkcS3iEhLJO6l3dgpQqZF\nwqQlElGkCVOEEAmMEbf8PXaKkCWR3otLekUyVQgzFTamSAu5IYtIQpgKG1OkCU8RQqQwmDo3\nTYWlRwrRlF6TIBRMEQqwTURaHkwRCrBNRFoeTBEKsE1EWh7MbAixUUxaHIjku4G+4pJWkUwV\nwkyFRSRE0oqpsIiESFoxFXZxIh1eNx2mKa0mQSiizmwY/bCIYCKd3tpFJJAgokiH9CKdCkSC\nIMS8tDsVY5+vGkikg1sjEgQh6hjpNPb5qpJn99qVd39/3fa22d37ZNlAzmLSwohbbDi05q0G\nauKNczU/tiguN5F7Zp0HqdppFclUIcxUWDtVu3/j6NnYwe2ve/dz3zIiWcFUWDsiebB2B7dp\ntoxIVjAVdhEinZ1z52bLkcZISk2CUCxBpOvuWeRAJAjCEkSiR4LgLEGkzW2M1NzBQiQIwgJE\n+rld2O3d4b7lWCJh0rLIX6RLUd1Hul/cxara6RTJVCHMVNgFiLS9z2yoL+4QyQymwi5ApNBN\nIVIgTIVFJMZIIAEiBdsyJi0JRAq2ZURaEogUbMuItCQQKdiWEWlJIJLvBj4Xl/SZZKoQZios\nIiGSVkyFRSRE0oqpsIgUsCl9IkEwliXSYeWKXfcLZUL+Npi0HBYl0q56oF7RMQmRQIIliXRy\n20v5LJRt+KZqEGk5LEmkTb3Z7gRwRAIJ8hep9YDI+8ZlRRoqLmkzyVQhzFTYBYjUekBkxcV1\nHpyMSFoxFdaOSH/j6NlY5wGR5dvjl6amgUiBMBXWjkgetB8QeT0Xm84fBv1ttIkEwViCSO3H\ncV1evxEj7G+DSUthCSK1HxC5XoVt6gVEWgpLEOnZI51X6/PLHyISSLAEkR4PiDy69286QySQ\nYAEiPR4Qee7xKGzVTptIpgphpsIuQKTnAyK3fV9fG1YkZSaZOjdNhV2ASM8HRPZ+DzQiacVU\n2AWIlLYpXSJBMJSK1PxrFH7pIrXDMu+lTpH+uweMsHSBt/8v8u/DMs1Sp0j5XNpxbbcQECnw\n9hFpGSCS7waay+QPqBLpS1ZdmAqLSKFFUmWSqXPTVFhEQiStmAqLSMGb0iQSBAORQjeASIsA\nkYK3gElLAJGCt4BISwCRgreASEsAkXw38LW4pEgkU4UwU2ERKbxIikwydW6aCotIiKQVU2ER\nKUJTekSCYCgVKSLhfxtEWgBKRQrfREwwKX8QKQKIlD+IFAFEyh9E8mVEcUmNSKYKYabCIpI3\nY463FpNMnZumwiKSN4gUCFNhESkOWkyCUCBSFBApdxApCoiUO4gUB0zKHESKAyJlDiL5Mq64\npEMkU4UwU2ERyZuRx1uFSabOTVNhEckbRAqEqbCIFA0VJkEoECkWiJQ1iBQLRMoaRIoGJuUM\nIkUDkXIGkXwZXVxSIJKpQpipsIjkzfjjnd4kU+emqbCI5A0iBcJUWESKSXqTIBSIFBFEyhdE\niggi5UtUkX73m+rhppvdb6gmdINJ2RJRpMuq9aDgdZAmtINI2RJRpJ0rfk7Vq/OxcLsQTaRg\nSnEptUimCmGmwsYUqXCnx+uTK0I0kYJJxzuxSabOTVNhY4rU+eKH4W+BQKQwmDo3TYWlR4pM\n6os7CETcMdLxXL3Kaow0DUTKlJjl73Wrare6BGlCPYiUKXHvI+2q+0jFZr/Q+0hXTMoVZjZE\nBpHyBJF8mVhcSiqSqUKYqbBMEfJm6vFOaZKpc9NUWKYIeYNIgTAVlilC8WGUlCPckI0OIuUI\nU4Sig0g5Qo8UH0zKEKYIxQeRMoQpQr5MLy6lE8lUIcxUWKYIeTPjeCczydS5aSqs1pkNzU40\nsKxeTvt7/1Ll/U/B/hq9bP6fOse4pR6RWtd9rjngLFkaWTJFKAWUG7KDKUIpQKTsYIpQEjAp\nN7ghmwREyoi/iul/jylCHZrCzSQSiTQraypUh/1rUf2AHsmXecc7jUmqz81X9IV9lacNU4R8\nQaRAKAk7ZE8LpgglglGSYt4u3L7DFKFEIJIyZsjTRs/MhshNpAaRNOAnTxtESgUmJcKz6/lA\nTJHOW1fsr9fDyhWDpQZEAmHCyNMm5hShohwgHfaZTRGaW1xKIZKSQtg4/MOGlqdN1PL3rR/a\nFW57uV52Sy9/X5OYtBCR4unzJOoN2epvu6rwvfQbsldE+sbksBH7n3eiP0XoPjconylC82GU\nJENKfx4k6JHK/17y6ZHmg0h+qBCoIcEYaXe5v5ZvwhaINBNNAjVQtUsIJk1Eo0F3uI+UEEQa\ni2KD7jCzwRePSlh0kexV7fQbdAeRfPE5OWObZEikv7///jNh0B1E8gWRZHn0QRbCPkGkpDBK\nemLmKq4XREoKIpWYNugOIiVl4SLZ7oQ6IFJalmpSPgbdQaS0LE+k7BSqQSRf/IpLcUVKWwib\nqBBVO3+WI1Jck1Kdm7N6IUTyB5HCEP/c9LiQQyR/LInkS66jpEzHQp9ApNRkKNKyFKpBpNTk\nJdISHapApOTkYtJiHapApORkINKyHapAJF+8i0sRRQpRCAvmEFU7fxYlUkSThM/NsB0RIvmD\nSGGQOzcjXMwhkj+WRBLA2CiJAVEPiKQAQyIh0QcQSQFGREKiARBJA/pNQqIvIJIGdIuERCNA\nJF8kikuxRJqeNaFEVO38WZpIsUyaljVxT4RI/iBSGMZnVXA5h0j+WBJJBk2jJAUS2QORdKBG\nJCSaByIpQYNJdEXzQSQlJBcJibxAJC2kNImuyBtE8kWquBRDpN6sWiWiaufPEkWKYdJbVs1d\nESL5g0hh6GZVLFEJIvljSSQ5Yo6SNHdFJkEkPUQTCYnkQSRFxDCJrigMiKSI4CIhUTAQSRNh\nTcKigCgVqanYGFhWL4W29y9czvsXhaffX6OXzf9T5xi31ClSc8AtLOvjnT5Hdstq3yrIMW6p\nUyRLl3bNP0oiBLm2e17SiWYNjamwWi/twjehFHGTqC/EAZF0ISsSFkUDkZQhaBIWRQSRlCEl\nEp1RXBBJGyImYVFsEMkX6eKSv0ifOyNThTBTYRHJG/Hj7WfS4CWdqXPTVFhE8kaVSF8u6Uyd\nm6bCIpJC5ppEfSEhiKSPeSJhUVIQSSEzTEKjxCCSQiaLhEbJQSSNTDMJjRSASL6EKC5NEWmK\nRqYKYabCIpI3QY73aJOm9Uamzk1TYRHJm5QiTb2oM3VumgqLSEoZYxJjI0Ugkk6+i4RGqkAk\npXwxCY2UgUhaGTIJjdSBSFr5LBIaKQSRfAlWXPpgko9GpgphpsIikjdxRfLrjUydm6bCIpI3\n4Y73u0m+F3Wmzk1TYRFJMa8iMTZSDCIppmMSGqkGkRTTEgmNlINImnmYhEbaQSTNNCLhkXoQ\nyZegxaXKJLnLOlOFMFNhEcmb4CIJdkemzk1TYRHJm7DH+59olcHUuWkqLCIph9GRERBJM7fu\nKPg3nYMIiKSYsjtCJBsgkl7qyzpMMgEiaaWpMiCSCRDJl0DFpWeVQdAkU4UwU2ERyZsgx7td\n9EYkC0QV6Xe/cSWb3W+oJuIT4nh3i95yJpk6N02FjSnSZeWerIM0kQkvN48YJRkgokg7V/yc\nqlfnY+F2IZrIgve5DJikn4giFe70eH1yRYgmcqBnLgMi6SeiSM59eiPWhH36p9ZhknrokVTx\nYWodIqkn7hjpeK5eZTVGEiwufZ7pLWSSqUKYqbBRy9/rVtVudQnSRALkjvfATG9E0k7c+0i7\n6j5SsdlzH+mdwU9MyJhk6tw0FZaZDVr48gE+RknKQSQdfP0AHybphilCKvj+QVhE0g1ThDQw\n5gPlmKQapggpYNyDGTBJM9yQ9cW/uDTyAScCIpkqhJkKyxQhb3yP9/jnbfmbZOrcNBWWHskb\nz+M95Xlb3iaZOjdNhWWKUGKmPbeOYZJafES6bJ1bH+8/HLGhPKcIeTHx+Y+IpBYPkS5FfVOo\n/uGYDWU5RciHyc9RxSSteIi0c4ebTYeiuiU0SqTxTTTXx3kv/5TkYOm/9BCpqF+ci9VZQqTW\ndd/No//u+XJe/inJwVJg6SFS485lvR57aZfjFKHmH6XJzHs+vtfF3eysKTAV1ufSbuWagsFq\nPUakTKcIzT3ec79nwsckU+emqbA+Ih3c9v7q7NYjRMp0itDM4z3/+1o8TDJ1bpoK61X+3j3s\nOboRImV6Q3YeHt97ROVOI143ZE+b5tV5+31DmU4RmoPf1/BhkkKYIpQA36/hwyR9MEUoPt5f\nZ4lI+vAUadsU7s7DZbgKpghVCHwtLCapw1MkV/xUy8NypwhNLS6JfL3yTJNMFcJMhfUV6bdw\nm/OtO3LFFzXmN6Gdicdb6GvK55lk6tw0FdZ/jLR3bufcXihObxO6mXa8hTxCJG34FxtuV3Xl\n7NURXHZlqW6/cm79I57KBlIeMUzShlCPNFiDu3MubgOp+2cvMpoiNAU5jzBJGf5jpPVtjLQZ\nM0baus3l9p/tubp/u8Tyt6RHiKQL36rd/arupxgzs+Fy/8/tKm+JN2RFPcIkXXiKtD7fX1y2\nfat2/175FxvhljdFyG9aUB+YpAifj1HsjpP+3racIrSv5wldhgdJlkQaWVwS1+g6wyRThTBT\nYX1EqmoG326ttji5Yne6boqbSceVG5QwP5FCeIRIivB5+MlxW5XgNofz4PoPjsVzitDwjafs\nRAri0XSTTJ2bpsL6jpHOP/Wkn+3P4Ny5hp9t9SnZzf6LepZEGkMgjxgm6UFg9vdpX81GFYnz\noQnjBPMIkdQg9DGK393KO8qXJuwSziNMUgPf2BeekCJhkhIQKThBPcIkJSCSL9+KS4E9miSS\nqUKYqbCI5E1qkaaYZOrcNBXW94Zsi8SpkvHleAf3aIpJps5NU2H9HhCJSF+J4BGjJA34XNqd\nihFPPJkFIk0Ck9Lj94DIUR/om0E2IkXxCJMU4FdsOLSe+ShJLiJF8giT0kPVLiSItBgQyZeB\n4lI0j8aaZKoQZiosInnz+XhH9GikSabOTVNhoz6yeF4T2vl4vKN6hEiJifrI4llNmCWuSAyT\n0sIji0MR2SNMSguPLA5EdI8wKSkxH1k8uwmLINKyiPjI4tlNWCSBR5iUkoiPLJ7ZhHZ6i0tJ\nPPpukqlCmKmwMR9ZPLMJ7WgS6ZtJps5NU2FjPrJ4ZhPa6TveqTz6ZpKpc9NUWGY2hCCdR4yT\nUoFIAUCk5YFI8qT0CJMSgUjipPUIk9KASOKkFgmTUoBIvrwWl5J7NGCSqUKYqbCI5M3L8Vbg\n0WeTTJ2bpsIikjcaRfpkkqlz01RYb5F2Bc+1a6PDI8ZJ0fEUaccDIjto8QiTYiM0104YRPIH\nk6LiLZJYkk9NWEKRR4gUF+9Lu1HfHevThCE0eYRJcfEtNqzXI7/SfH4TymkVl3SJ1GOSqUKY\nqbDeIh0XX2x4Hm9lHvWYZOrcNBXWV6Q9VbvH8Vbn0btJps5NU2F9RSoCVe2anWho+ackB8sk\nS51Vu//uAS0t/5TkYJlk6X1pR9WuRuGFXQW1uzj4Fhv2a9HHB/U1YQKtHmFSJLwv7RZfbKhB\npIWDSL5Ul8l6PeqY1IyNTWAqLB+j8KY83po9aptk6tw0FRaRvNEv0tMkU+emqbCIJIFyjxgn\nRYAxkj/qPcKk8CCSPwZEwqTQyFza/a43/lGGm9CLBY8wKTRCY6SLW+xD9I2IhElhkSo2LPfS\nzkxx6Z+hrCWmwkqJdHCFd5QvTWjFzPFGpJCIFRtEv47ZkEh/do73P1vnpqmwUiKtZD+WZEmk\n1AEmwDApHNyQ9cSSSJgUDkTyw5RHmBQORPLDmEiYFAqe/e2FNY8wKRQ8+9uLP1vFpTLrPysq\nWdqxPPvbE4MimemULO1Ynv3tR/3koNQpxnPPasMkSzuWZ3/7YW+IVGPDJFPw7G8PrHqESfLw\n7G8P7IqESdLw7O/5GPbIUPHOCEqf/R1io+KYFolOSRaqdvOpRbJUXOpmVW6SpR0rcGm33Krd\nvUOydLxfsuo2ydKO5dnfHtgXSbdJlnYsTxGaj/ERUo1qk0yBSHPJQiSKd1LwMYq55CESnZIQ\niDSTXDzCJBk8RCqv5pZ7aZePSJgkASLN4+mRpeLSh6w6TbK0Y7m0m0tWIuk0ydKORaS55CWS\nyuKdpR0rN0WoWNaTVjMaId1RaJIphEQ6L2yMlJ9ImOSHh0hH12Y14m/+7jfVupvdl3lF2kXK\n0CNM8sOnR1q1Pfo+5e7SXn8tnSoqWYqEST5E/BjFzhU/p+rV+Vi4nXCqqOQpEiZ5ELFqV7jT\n4/Vp+GtglIvU8chScelbVlXFO0s7VkCkn3LYsz2O+XvjuzJECsP3rIpMsrRjBZ4idB/zjPgO\n2Wx6pO6FnaXjPSKrHpMs7ViB59oVZWd0HPPshnLd+tldxsdImY6Q7ugxyRTeDz+pe5nTmPL3\nul3lG/yIOiIlRNVAyQxSVbtR5bvfXXUfqdjsLd9HytyjK53SHLwv7ZoeacQgaV4T6shfJDql\n6Xg//KQaI/0WwzdYvZpQxgI8utIpTUbumQ0jPpOUxRShV5EsFZcmZE3fKVnasVFFymOK0FuH\nZOl4T8qa2iRLOzbqzIY8pggtR6TUJlnasUwRmswyhkg16S/v7OA/Rai8O7T5GfP3cpgitCSP\nrsk7JUNITREaUbXLokdamEh0SmPxFOmwsClCS/PoSqc0Ek+RVgubIrRAkeiURsEUoUn0iGSp\nuDQzaxqTLO1YwR5J9ilCzU5Utvzr+Xn1Ukm+b8v/Zv69fynyNv+P3e68ZcQx0rfNtmgOuIVl\nfbzT58huWe1bBTnGLSNW7exPEVriCKmBkdIwMh81H3Ufyf4UoSWLRPluGKYITWDZImHSEEwR\nGs/CPeLyboiIIpmfIrR4keiUPkOPNJoPHjUVUAv4Z43YKVnasbHHSKanCCFSRTSTLO3YuN+P\nZHyKECLVxOqULO3YyF80ZnqKECOkB4yU3uEb+8aCSE8o372BSCPBow6o9EISkb5OFUck/WBS\nB0QaCSK9QqfUJuoN2dGP7tIn0mePLBWXhLOGNcnSjo0q0m+BSImRzhq0U7K0Y+Ne2l02bl3d\nkbV3aTdwYWfpeMtnDaiSpR0be4z041z5gYusRFo6jJQqIhcbzmu3uSBSVlB0KIletdu74mhO\nJDwaBJNSlL9Pq+9fW4FItqBTSnIfaWtNJDz6yuJVYorQCAZFslRcCplV3CRLOxaRxjDcIVk6\n3kGzSndKlnYsIo0BkUYiq5KlHYtIY2CINJrljpQQ6St4NIHFFh0Q6SuINImFmoRI38CjiSyz\nU0KkbyDSZJaoEiJ945tIlopL0bJKqGRpxyLSV752SJaOd8Ss/ipZ2rGI9BVEmouvSpZ2LCJ9\ngxGSB0saKyHSMIjkxXJUQqRhEMmTpaiESMMgkjfLUAmRBsEjCZagEiINMkIkS8WlZFnnqGRp\nxyLSFxBJiukqWdqxiPQFRJJjqkqWdiwifYExkiQ5j5UQaRBEkiVflRBpCDwSJ1eVEGkIRApA\nnioh0hCIFIQcVUKkIcaIZKm4pCbrGJXUhB0FIg2BSMH499UlRWFHgEgDjLqys3S8dWX9opKu\nsN9ApAEYIgXme7dkBkQaAJHCk4tKiDQAIsUgD5UQaQBEikMOV3iI9Bk8iod5lRDpM+NEslRc\n0pz1rVvSHPYdRPoMIkWmq5LysC8g0mcQKTrtbkl92A6I9BnGSCkwOlpCpM8gUhpMqoRIH8Gj\nZBishyPSRxApJdZUUipSM9BMufxL3P7Sl2W3pCHHuKVOkf67B0y6/Bu3XvlSRd7cltW+VZBj\n3FKnSJYu7Zp/lCxgKes9rJVLPET6xNghkqWT01LWR1gblQdE+gS1Bj0YcAmRPoFIqtCuEiJ9\nApGUobtbQqRPIJI+FLuESB/AI51oVQmRPjBaJEuVMEtZP4bV2S0h0gcQKTUDYRW6hEgfQKTU\nDIfVphIifYAxknZ0dUuI9AFEMoAilxCpHzwyghaXEKkfRLKDCpcQqR9EMkV6lxCpn/EiWaqE\nWco6NWxilxCpH0RKzvSwKV1CpF4mXNlZOjktZZ0X9l8qmRCpF4ZIhkniEiL1gki2ie8SIvWC\nSOaJ7BIi9YJIORDTJUTqBZEyIZpLiNTHFI8sVcIsZRULG6eQh0h9IJICJMOGdwmR+kAkBQiH\nDdwxIVIfDJHyJKBLiNQHImVLqI4JkXrAo7wJ4RIi9YBI2SPeMSFSD4i0CERdQqQeJolkqRJm\nKWuUsHIdEyL1gEgaiBVWRiZEemfalZ2lk9NS1qhh/WVCpHcYIi0SP5kQ6R1EWiz/ZtuESO8g\n0rKZJRMivYNIMLlrQqR3EAkqpsiESG9M9MhSJcxSViVhx8oUVaTf/caVbHa/oZoQAJF0oCfs\nmOu8iCJdVu7JOkgTIiCSDpSF/SJTRJF2rvg5Va/Ox8LtQjQhAkMk+MCATBFFKtzp8frkihBN\niIBIMMAHmSKK5NynN2JNSIBH8I2eQRM90iuIBKPoyhR3jHQ8V69Uj5EQCUbzlClm+Xvdqtqt\nLkGaEGCqSMqKS4NYymombC1T3PtIu+o+UrHZK76PhEhKsBT23z9mNryCSEowFZYpQq8wRII5\nMEXoBUSCOTBF6AVEgjkwRegFRII5cEP2BUSCOTBFqMt0jywVlyxltRWWHukFRFKDqbBMEXoB\nkdRgKixThF5giASzYIpQF0SCWSid2dB06yxZ2ljqEal13XfzqA7IkqWRJVOEOnBlB/NgilCH\nGSI1vbsFLGW1FZYpQl0QSQ+mwnJDtgsi6cFUWKYIdWCIBDOhR2qDSDATpgi1QSSYCVOE2iAS\nzIQpQm0QCWaiZ2ZD5Cb6mOWRpeKSpay2wiJSG0TShKmwUUW6bJ1bH+8b0Vj+RiRNmAobdYpQ\nUU+0qzeSjUgA18jl78PNpkNRTbNDJMiKqDdkq8W5WJ11ioRHMJsEU4Qu6zUiQWZEFGnlmpuw\nqzUiQV5EFOngtvdXZ7fORyRLxSVLWW2FjVr+3j3sOTpESoGlrLbCxr0he9o0r85bREqApay2\nwjKz4QlDJPjxr+4AAAe8SURBVJgPIj1AJJgPIj1AJJgPIj1AJJgPIj1AJJgPIjXM9chScclS\nVlthEekBIinDVFhEeoBIyjAVFpEeMEQCDxCpAZHAA0RqQCTwAJHu4BH4gEh3EAl8QKQ7s0Wy\nVFyylNVWWERqQCRtmAqLSA2IpA1TYRHpDkMk8AKRahAJvECkGkQCLxCpBpHAC0SqQSTwApEq\nPDyyVFyylNVWWESqQSR9mAqLSDWIpA9TYRGphiES+IFIFYgEfiBSBSKBH4hUgkfgCSKVIBJ4\ngkglPiJZKi5ZymorLCJVIJJCTIVFpApEUoipsIhUwhAJfEGkKyKBP4h0RSTwB5GuiAT+INIV\nkcAfRLp6imSpuGQpq62wiHT17ZAsHW9LWW2FRaQrIinFVFitIjU7McryL1I7LDNe6hTpv3vA\nOMu/yO2xzHCpUyRLl3YAV7WXduGbeIJH4A8iIRIIgEi+IjXjTQtYymorLCIhklZMhUUkRNKK\nqbCIxBAJJEAkRAIBEAmRQABEQiQQAJEQCQRAJF+RLBWXLGW1FRaRvDskS8fbUlZbYREJkbRi\nKiwiMUQCCRApXlOQMYgUrynImKWLhEcgAiIBCIBIvlgqLlnKaissInlvwdLxtpTVVlhE8t6C\npeNtKautsEsXiSESyIBIAAIgEoAAiAQgACIBCIBIvlgqLlnKaivswkWS6JAsHW9LWW2FRSRv\nLB1vS1lthUUkAAkQCUAARAIQAJEABEAkAAEQyRdLxSVLWW2FRSRvLB1vS1lthUUkbywdb0tZ\nbYVFJAAJFi0SHoEUiAQgACIBCIBIAAIgki+WikuWstoKi0jeWDrelrLaCotI3lg63pay2gqL\nSAASIBKAAIgEIAAiAQiASAACIJIvlopLlrLaCotI3lg63pay2gqLSN5YOt6WstoKi0gAEiAS\ngABLFgmPQIyoIv3uN65ks/sN1cQUEAnEiCjSZeWerIM0MQ1EAjEiirRzxc+penU+Fm4Xoolp\nyIhkqbhkKautsDFFKtzp8frkihBNTAORVGMqbEyRnPv05v6T2PyJbOW//0Q2EwVLWW2FfT+f\nw4mkrkcSwlJYS1mzD+sxRjqeq1dKxkhCWAprKWv2YWf/futWR7i6BGkiBZbCWsqafViP+0i7\n6j5SsdmruI8khKWwlrJmHzabmQ1CWAprKWv2YRGpi6WwlrJmHxaRulgKaylr9mERqYulsJay\nZh8WkbpYCmspa/ZhEamLpbCWsmYfFpG6WAprKWv2YRGpi6WwlrJmH9bU7wegFUQCEACRAARA\nJAABEAlAAEQCEACRAARAJAABEAlAAEQCEACRAARAJAABEAlAAEQCEACRAARAJAABREXaFa7Y\nXfp/0P8yIePCzn6ouihDWa/Xg/u0WhLGhdWxYwfDHlYTTlnJ36R+ivGq9wf9LxMyLuxJxfEe\nylpl/LBaEsaF1bFjB8PuqpfFpW+1dwR/k19XnK6nwv32/KD/ZUJGhj25TcqUb9F6fnBbuv7V\nkjAyrIodOxj25LaXsgPdjtuzgiLt3PH23x+37/lB/8uEjAx7SByzYijrLeH6fm7q37GtsCp2\n7GDYTR20zDtmzwqKtHHl97y0/qlp/aD/ZUJGhj24Q7KID4ayXt2u+Z43/Tu2FVbFjh0OW1Pm\nHbNnBUVyrr3o/qD/ZUJGht244/Y2zEwQsMVQ1uvp9c8V79hWWBU7djhsxaX8pvExexaR3n/Q\nEali+GvbQ/PtcNsR6blUsWNHiHQor+oQ6TOjw/7c/lXapb0OyVEkFTv2u0jnYtO3Wt+m4qSy\nKlLNJW1NOUeRahLv2K9hL8W6d7W+TcmlKl6ba/2g/2VCRoa9kzbsUNbWUv+O7f7B+7vofAu7\nXvWv1oPgL1LXNs6vJZDzsxD2+jIhI8PeSXu8h7KWPIYd2ndsiSqRhsOeV+tz/2o9CP4i+6ra\nfnx+xXnrB/0vEzIybOHKG9uJT86hrCX3s1H/ji15dJ8Kduxw2OOjFDJmzwqKlOPMhl258y71\nDTmVWUvu56b+HVtyD6tixw6GPT9LipFnNlxXz4pmvbtaP+h/mZBxYS9F9TLx/Y6hrNfn9ZH+\nHfv4mZIdOxR2657TAUfsWUmRLtUc2eszVesH/S8TMiHsKvVN+KGs16dI+nfstRs2+Y4dCuta\nIo3Ys2kHewCZgEgAAiASgACIBCAAIgEIgEgAAiASgACIBCAAIgEIgEgAAiASgACIBCAAIgEI\ngEgAAiASgACIBCAAIgEIgEgAAiASgACIBCAAIgEIgEgAAiASgACIBCAAIgEIgEgAAiASgACI\nBCAAIgEIgEgAAiASgACIBCAAIgEIgEgAAiASgACIBCAAIgEIgEg2OW6cgm8whweIZJJ9/c31\nmKQGRDKJcz/X64/j6KmBQ2EYRNIDh8Io5+N+jUh64FDYZF0PklLHgAYOhUm2bnU4nhFJDxwK\nk1QKIZIiOBQmce73emKMpAgOhUl29RDpphPoAJFssnVu/Xt0m9Q54A4iAQiASAACIBKAAIgE\nIAAiAQiASAACIBKAAIgEIAAiAQiASAACIBKAAIgEIAAiAQiASAACIBKAAIgEIAAiAQiASAAC\nIBKAAIgEIAAiAQiASAACIBKAAIgEIAAiAQiASAACIBKAAIgEIAAiAQiASAACIBKAAP8D1ooA\ndF3tC3gAAAAASUVORK5CYII=",
            "text/plain": [
              "Plot with title \"Figure 2.5/2.6 Book\""
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RK3ByFq-D6x",
        "colab_type": "text"
      },
      "source": [
        "The book uses the derivative to estimate what would happen, our results are what actually happens when you change the result by 10%. Understanding what the book is doing and how it is using the derivative to get the estimate is fine and will definitely help you understand what we actually need to do with the computing power that we have in R.\n",
        "\n",
        "Each one of the function calls below is an optimization of the parameters with a different value for elasticity. We built a table with all of the values that you need above, but below is how you would use those values in the table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYMUOY0O-D6z",
        "colab_type": "code",
        "colab": {},
        "outputId": "6801410a-f9ca-435f-b9d8-3dad244b7eb9"
      },
      "source": [
        "## If we are only interested in what happens at a 10% increase in elasticity\n",
        "(P(0.011)$par[1]-P(0.01)$par[1])/P(0.01)$par[1]\n",
        "(P(0.011)$par[2]-P(0.01)$par[2])/P(0.01)$par[2]\n",
        "paste(c(\"Here are the numbers from the table that were used in the first calculation:\",\n",
        "        P(0.011)$par[1],P(0.01)$par[1]),collapse=\" \")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "-0.102412735499731"
            ],
            "text/latex": "-0.102412735499731",
            "text/markdown": "-0.102412735499731",
            "text/plain": [
              "[1] -0.1024127"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.0240732352178718"
            ],
            "text/latex": "0.0240732352178718",
            "text/markdown": "0.0240732352178718",
            "text/plain": [
              "[1] 0.02407324"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "'Here are the numbers from the table that were used in the first calculation: 4250.12157764057 4735.05111506547'"
            ],
            "text/latex": "'Here are the numbers from the table that were used in the first calculation: 4250.12157764057 4735.05111506547'",
            "text/markdown": "'Here are the numbers from the table that were used in the first calculation: 4250.12157764057 4735.05111506547'",
            "text/plain": [
              "[1] \"Here are the numbers from the table that were used in the first calculation: 4250.12157764057 4735.05111506547\""
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS_IxaC0-D64",
        "colab_type": "code",
        "colab": {},
        "outputId": "36badddc-e79d-46c2-e45f-160aa767e4ad"
      },
      "source": [
        "## Use the data frame to produce Figure 2.7 ##\n",
        "## Note the very strange way of slicing the data ##\n",
        "print(ans.profit[3:length(ans.profit)])\n",
        "plot(result$a[3:length(result$a)],ans.profit[3:length(ans.profit)]/1000,xlab=\"a\",ylab=\"Profit(in 1000s)\",\n",
        "     type=\"l\",col=\"blue\",lwd=3,main=\"Figure 2.7\")\n",
        "grid(lwd=2, nx=4, ny=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " [1] 979027.0 814225.2 718449.7 655844.1 611719.4 578945.3 553641.0 533514.1\n",
            " [9] 517123.0 503515.9 492039.1 482228.7 473746.2 466339.1 459815.2 454025.3\n",
            "[17] 448852.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAANlBMVEUAAAAAAP9NTU1oaGh8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\nAABJRU5ErkJggg==",
            "text/plain": [
              "Plot with title \"Figure 2.7\""
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIvFgTDH-D68",
        "colab_type": "text"
      },
      "source": [
        "From page 29, the author is interested in a 10% increase in price elasticity and the effects on the profit level. Our calculations are that a 10% increase in price level will result in a 3.6% decrease in profits (see next R calc). You can also use the table above to get the same calculations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omF8ouB5-D6-",
        "colab_type": "code",
        "colab": {},
        "outputId": "e9c12874-6823-451c-dc3f-c32f6e723aff"
      },
      "source": [
        "(P(0.011)$value-P(0.01)$value)/P(0.01)$value\n",
        "\n",
        "## Table values ##\n",
        "a[10]\n",
        "ans.profit[10]\n",
        "a[9]\n",
        "ans.profit[9]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "-0.0363538125884563"
            ],
            "text/latex": "-0.0363538125884563",
            "text/markdown": "-0.0363538125884563",
            "text/plain": [
              "[1] -0.03635381"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.011"
            ],
            "text/latex": "0.011",
            "text/markdown": "0.011",
            "text/plain": [
              "[1] 0.011"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "533514.063552283"
            ],
            "text/latex": "533514.063552283",
            "text/markdown": "533514.063552283",
            "text/plain": [
              "[1] 533514.1"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "0.01"
            ],
            "text/latex": "0.01",
            "text/markdown": "0.01",
            "text/plain": [
              "[1] 0.01"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "553641.025640222"
            ],
            "text/latex": "553641.025640222",
            "text/markdown": "553641.025640222",
            "text/plain": [
              "[1] 553641"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVlI7oBv-D7C",
        "colab_type": "text"
      },
      "source": [
        "## Sensitivity - what do we really lose if a = 0.011 instead of a=0.01\n",
        "In the book on page 30-31, the author tries to convince you that the answer is quite robust. Let's actually do the calculations to confirm or deny that. Assume that we solve the model using a = 0.01, and let a actually fluctuate (he used 10%, but we can test a lot using R.<br>\n",
        "#### Recall the solution, x1=4735 and x2=7042 ####\n",
        "Now let's see what happens to our profit as a goes from 0.01 through 0.02 by 0.001. We will compare the profit made by producing (4735,7042) with the optimal solution for each scenario (a)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QPpxhJu-D7D",
        "colab_type": "code",
        "colab": {},
        "outputId": "bb63f2df-05b7-4bbe-c854-78ec6e1434b0"
      },
      "source": [
        "P1 = function(a){\n",
        "    f = function(x){((339-a*x[1]-0.003*x[2])*x[1]\n",
        "           +(399-0.004*x[1]-0.01*x[2])*x[2]\n",
        "           -(400000+195*x[1]+225*x[2]))*-1\n",
        "    }\n",
        "    x = c(4735,7042) \n",
        "    return(f(x))\n",
        "}\n",
        "a = seq(0.01,0.02,0.0005)\n",
        "ans.profit = 0\n",
        "ans.maxProfit=0\n",
        "for (i in 1:length(a)){\n",
        "    ans.profit[i]=-P1(a[i])\n",
        "    ans.maxProfit[i] = -P(a[i])$value\n",
        "}\n",
        "result = data.frame(a=a,change=(a-0.01)/0.01,profit=ans.profit,max_profit=ans.maxProfit,\n",
        "                    diff=round((ans.maxProfit-ans.profit)/ans.maxProfit,4))\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        a change   profit max_profit   diff\n",
            "1  0.0100   0.00 553641.0   553641.0 0.0000\n",
            "2  0.0105   0.05 542430.9   543035.0 0.0011\n",
            "3  0.0110   0.10 531220.8   533514.1 0.0043\n",
            "4  0.0115   0.15 520010.7   524919.7 0.0094\n",
            "5  0.0120   0.20 508800.6   517123.0 0.0161\n",
            "6  0.0125   0.25 497590.5   510017.7 0.0244\n",
            "7  0.0130   0.30 486380.3   503515.9 0.0340\n",
            "8  0.0135   0.35 475170.2   497543.8 0.0450\n",
            "9  0.0140   0.40 463960.1   492039.1 0.0571\n",
            "10 0.0145   0.45 452750.0   486949.1 0.0702\n",
            "11 0.0150   0.50 441539.9   482228.7 0.0844\n",
            "12 0.0155   0.55 430329.8   477838.9 0.0994\n",
            "13 0.0160   0.60 419119.7   473746.2 0.1153\n",
            "14 0.0165   0.65 407909.6   469921.4 0.1320\n",
            "15 0.0170   0.70 396699.4   466339.1 0.1493\n",
            "16 0.0175   0.75 385489.3   462976.9 0.1674\n",
            "17 0.0180   0.80 374279.2   459815.2 0.1860\n",
            "18 0.0185   0.85 363069.1   456836.5 0.2053\n",
            "19 0.0190   0.90 351859.0   454025.3 0.2250\n",
            "20 0.0195   0.95 340648.9   451368.0 0.2453\n",
            "21 0.0200   1.00 329438.8   448852.2 0.2660\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}